  ai-sarif-analyzer:
    name: AI-Powered SARIF Analysis
    runs-on: ubuntu-latest
    needs: [semgrep-scan, trivy-scan, codeql, tms-scan]
    if: always()
    permissions:
      contents: read
      security-events: write
      pull-requests: write
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
      
      - name: Download all SARIF results
        uses: actions/download-artifact@v4
      
      - name: Install AI Analysis Tools
        run: |
          pip install anthropic jq
      
      - name: Aggregate and Analyze Findings
        env:
          ANTHROPIC_API_KEY: ${{ secrets.ANTHROPIC_API_KEY }}
        run: |
          cat > intelligent_analysis.py << 'EOF'
          import anthropic
          import os
          import json
          import glob
          from collections import defaultdict
          
          client = anthropic.Anthropic(api_key=os.environ.get("ANTHROPIC_API_KEY"))
          
          # Aggregate all findings
          all_findings = defaultdict(list)
          severity_counts = {"critical": 0, "high": 0, "medium": 0, "low": 0}
          
          for sarif_file in glob.glob("**/*.sarif", recursive=True):
              try:
                  with open(sarif_file, 'r') as f:
                      data = json.load(f)
                      tool = data['runs'][0]['tool']['driver']['name']
                      results = data['runs'][0].get('results', [])
                      
                      for result in results:
                          rule_id = result.get('ruleId', 'unknown')
                          message = result.get('message', {}).get('text', '')
                          level = result.get('level', 'warning')
                          
                          location = result.get('locations', [{}])[0]
                          file_path = location.get('physicalLocation', {}).get('artifactLocation', {}).get('uri', 'unknown')
                          
                          all_findings[tool].append({
                              'rule': rule_id,
                              'message': message,
                              'severity': level,
                              'file': file_path
                          })
                          
                          # Count severities
                          if 'error' in level or 'critical' in level.lower():
                              severity_counts['critical'] += 1
                          elif 'warning' in level or 'high' in level.lower():
                              severity_counts['high'] += 1
                          else:
                              severity_counts['medium'] += 1
              except Exception as e:
                  print(f"Error processing {sarif_file}: {e}")
          
          # Prepare summary for AI
          summary = f"""
          ## Security Scan Summary
          
          **Total Findings by Tool:**
          {json.dumps({tool: len(findings) for tool, findings in all_findings.items()}, indent=2)}
          
          **Severity Distribution:**
          - Critical: {severity_counts['critical']}
          - High: {severity_counts['high']}
          - Medium: {severity_counts['medium']}
          - Low: {severity_counts['low']}
          
          **Sample Findings (first 10):**
          {json.dumps(list(all_findings.values())[0][:10] if all_findings else [], indent=2)}
          """
          
          prompt = f"""{summary}

As an expert security analyst, provide:

1. **Executive Summary** (2-3 sentences on overall security posture)
2. **Priority Fixes** (Top 5 issues to address immediately with clear reasoning)
3. **Risk Score** (1-10 scale with justification)
4. **False Positive Assessment** (Identify potential false positives)
5. **Remediation Roadmap** (30/60/90 day plan)
6. **Best Practices** (3 recommendations for this codebase)

Be specific, actionable, and interview-ready."""
          
          message = client.messages.create(
              model="claude-3-5-sonnet-20241022",
              max_tokens=3000,
              messages=[{"role": "user", "content": prompt}]
          )
          
          analysis = message.content[0].text
          
          # Generate markdown report
          report = f"""# ðŸ›¡ï¸ AI-Powered Security Analysis Report
          
{analysis}

---

## Detailed Findings

**Total Issues:** {sum(len(f) for f in all_findings.values())}

### By Tool:
{chr(10).join([f"- **{tool}**: {len(findings)} findings" for tool, findings in all_findings.items()])}

### Severity Breakdown:
- ðŸ”´ Critical: {severity_counts['critical']}
- ðŸŸ  High: {severity_counts['high']}
- ðŸŸ¡ Medium: {severity_counts['medium']}
- ðŸŸ¢ Low: {severity_counts['low']}

---
*Report generated by Claude AI | {tool} integration*
"""
          
          with open('AI_SECURITY_REPORT.md', 'w') as f:
              f.write(report)
          
          print(report)
          EOF
          
          python intelligent_analysis.py
      
      - name: Comment on PR
        if: github.event_name == 'pull_request'
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');
            const report = fs.readFileSync('AI_SECURITY_REPORT.md', 'utf8');
            
            await github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: report
            });
      
      - name: Upload AI Report
        uses: actions/upload-artifact@v4
        with:
          name: ai-security-report
          path: AI_SECURITY_REPORT.md
