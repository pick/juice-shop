name: DevSecOps Pipeline

on:
  push:
    branches: [ "main" ]
  pull_request:
    branches: [ "main" ]
  schedule:
    - cron: '30 1 * * 0'

permissions:
  contents: read
  packages: write
  security-events: write

jobs:
  tms-scan:
    name: 2MS Secret Scan
    runs-on: ubuntu-latest
    permissions:
      contents: read
      security-events: write
      actions: read
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
      
      - name: Run 2MS and save output
        continue-on-error: true
        run: |
          mkdir -p results
          chmod 777 results
          docker run --rm -v $(pwd):/repo checkmarx/2ms:2.8.1 git /repo --stdout-format json > results/2ms-raw.txt || true
          grep -A 999999 '^{' results/2ms-raw.txt > results/2ms-clean.json || echo '{"results":{}}' > results/2ms-clean.json
      
      - name: Convert to SARIF
        run: |
          python3 << 'PYTHON_SCRIPT'
          import json
          
          sarif = {
              "$schema": "https://raw.githubusercontent.com/oasis-tcs/sarif-spec/master/Schemata/sarif-schema-2.1.0.json",
              "version": "2.1.0",
              "runs": [{
                  "tool": {
                      "driver": {
                          "name": "2MS",
                          "informationUri": "https://checkmarx.com/product/2ms/",
                          "version": "2.8.1",
                          "rules": []
                      }
                  },
                  "results": []
              }]
          }
          
          try:
              with open('results/2ms-clean.json', 'r') as f:
                  data = json.load(f)
                  results = data.get('results', {})
                  
                  for commit_hash, findings in results.items():
                      for finding in findings:
                          rule_id = finding.get('ruleId', 'secret-detected')
                          source = finding.get('source', 'unknown')
                          start_line = finding.get('startLine', 1)
                          file_path = source.split(':')[-1] if ':' in source else 'unknown'
                          
                          if not any(r['id'] == rule_id for r in sarif['runs'][0]['tool']['driver']['rules']):
                              sarif['runs'][0]['tool']['driver']['rules'].append({
                                  "id": rule_id,
                                  "name": rule_id,
                                  "shortDescription": {"text": "Detected " + rule_id},
                                  "defaultConfiguration": {"level": "warning"}
                              })
                          
                          sarif['runs'][0]['results'].append({
                              "ruleId": rule_id,
                              "message": {"text": "Found " + rule_id + " in " + file_path},
                              "locations": [{
                                  "physicalLocation": {
                                      "artifactLocation": {"uri": file_path},
                                      "region": {"startLine": max(1, start_line)}
                                  }
                              }],
                              "level": "warning"
                          })
                  
                  print("Converted " + str(len(sarif['runs'][0]['results'])) + " findings to SARIF")
          except Exception as e:
              print("Error: " + str(e))
          
          with open('2ms-results.sarif', 'w') as f:
              json.dump(sarif, f, indent=2)
          PYTHON_SCRIPT
      
      - name: Upload 2MS SARIF to Code Scanning
        if: always()
        uses: github/codeql-action/upload-sarif@v3
        with:
          sarif_file: 2ms-results.sarif
          category: 2ms
      
      - name: Save 2MS SARIF as Artifact
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: 2ms-sarif
          path: 2ms-results.sarif

  build-and-push:
    name: Build and Push to GHCR
    runs-on: ubuntu-latest
    needs: tms-scan
    permissions:
      contents: read
      packages: write
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
      
      - name: Log in to GHCR
        uses: docker/login-action@v3
        with:
          registry: ghcr.io
          username: ${{ github.actor }}
          password: ${{ secrets.GITHUB_TOKEN }}
      
      - name: Build and push
        uses: docker/build-push-action@v5
        with:
          context: .
          file: ./Dockerfile
          push: true
          tags: |
            ghcr.io/${{ github.repository }}:latest
            ghcr.io/${{ github.repository }}:${{ github.sha }}

  semgrep-scan:
    name: Semgrep SAST Scan
    runs-on: ubuntu-latest
    needs: tms-scan
    permissions:
      contents: read
      security-events: write
      actions: read
    container:
      image: returntocorp/semgrep
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
      
      - name: Run Semgrep
        run: semgrep scan --sarif --output semgrep.sarif
      
      - name: Upload SARIF to Code Scanning
        if: always()
        uses: github/codeql-action/upload-sarif@v3
        with:
          sarif_file: semgrep.sarif
      
      - name: Save Semgrep SARIF as Artifact
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: semgrep-sarif
          path: semgrep.sarif

  trivy-scan:
    name: Trivy Container Scan
    runs-on: ubuntu-latest
    needs: build-and-push
    permissions:
      contents: read
      security-events: write
      actions: read
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
      
      - name: Run Trivy
        uses: aquasecurity/trivy-action@master
        with:
          image-ref: 'ghcr.io/${{ github.repository }}:latest'
          format: 'sarif'
          output: 'trivy.sarif'
          severity: 'CRITICAL,HIGH'
          exit-code: '0'
      
      - name: Upload SARIF to Code Scanning
        if: always()
        uses: github/codeql-action/upload-sarif@v3
        with:
          sarif_file: 'trivy.sarif'
      
      - name: Save Trivy SARIF as Artifact
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: trivy-sarif
          path: trivy.sarif

  codeql:
    name: CodeQL SAST Scan
    runs-on: ubuntu-latest
    permissions:
      contents: read
      security-events: write
      actions: read
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
      
      - name: Initialize CodeQL
        uses: github/codeql-action/init@v3
        with:
          languages: 'javascript'
          queries: security-extended
      
      - name: Perform CodeQL Analysis
        uses: github/codeql-action/analyze@v3

  ai-pr-review:
    name: AI PR Security Review
    runs-on: ubuntu-latest
    needs: [semgrep-scan, trivy-scan, codeql, tms-scan]
    if: github.event_name == 'pull_request'
    permissions:
      contents: read
      pull-requests: write
      security-events: read
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
      
      - name: Download SARIF results
        uses: actions/download-artifact@v4
        with:
          path: sarif-results
      
      - name: Install dependencies
        run: pip install anthropic
      
      - name: Create AI analysis script
        run: |
          cat > analyze.py << 'EOF'
          import anthropic
          import os
          import json
          import glob
          
          api_key = os.environ.get("ANTHROPIC_API_KEY")
          if not api_key:
              print("No API key")
              with open('pr_security_review.md', 'w') as f:
                  f.write("AI Security Review\n\nAPI key not configured")
              exit(0)
          
          client = anthropic.Anthropic(api_key=api_key)
          
          critical_alerts = []
          high_alerts = []
          medium_alerts = []
          all_tools = set()
          
          for sarif_file in glob.glob("sarif-results/**/*.sarif", recursive=True):
              try:
                  with open(sarif_file, 'r') as f:
                      data = json.load(f)
                      tool = data['runs'][0]['tool']['driver']['name']
                      all_tools.add(tool)
                      results = data['runs'][0].get('results', [])
                      
                      for result in results[:30]:
                          rule_id = result.get('ruleId', 'unknown')
                          message = result.get('message', {}).get('text', '')
                          level = result.get('level', 'warning')
                          
                          location = result.get('locations', [{}])[0]
                          phys_loc = location.get('physicalLocation', {})
                          file_path = phys_loc.get('artifactLocation', {}).get('uri', 'unknown')
                          line = phys_loc.get('region', {}).get('startLine', 0)
                          
                          alert_info = {
                              "tool": tool,
                              "rule": rule_id,
                              "message": message[:100],
                              "file": file_path + ":" + str(line)
                          }
                          
                          if 'error' in level or 'critical' in level.lower():
                              critical_alerts.append(alert_info)
                          elif 'warning' in level or 'high' in level.lower():
                              high_alerts.append(alert_info)
                          else:
                              medium_alerts.append(alert_info)
              except Exception as e:
                  print("Error: " + str(e))
          
          critical_json = json.dumps(critical_alerts[:5], indent=2)
          high_json = json.dumps(high_alerts[:5], indent=2)
          tools_list = ', '.join(all_tools)
          
          summary = "Security Scan Results\n\n"
          summary += "Critical: " + str(len(critical_alerts)) + "\n"
          summary += critical_json + "\n\n"
          summary += "High: " + str(len(high_alerts)) + "\n"
          summary += high_json + "\n\n"
          summary += "Medium: " + str(len(medium_alerts)) + "\n"
          summary += "Total: " + str(len(critical_alerts) + len(high_alerts) + len(medium_alerts)) + "\n"
          summary += "Tools: " + tools_list
          
          prompt = summary + "\n\nProvide a security review with: Executive Summary, Must-Fix items, Recommendations, False Positives, and Merge decision."
          
          message = client.messages.create(
              model="claude-3-7-sonnet-20250219",
              max_tokens=2000,
              messages=[{"role": "user", "content": prompt}]
          )
          
          analysis = message.content[0].text
          
          pr_comment = "## AI Security Review\n\n"
          pr_comment += analysis + "\n\n---\n\n"
          pr_comment += "### Scan Summary\n"
          pr_comment += "- Critical: " + str(len(critical_alerts)) + "\n"
          pr_comment += "- High: " + str(len(high_alerts)) + "\n"
          pr_comment += "- Medium: " + str(len(medium_alerts)) + "\n"
          pr_comment += "- Total: " + str(len(critical_alerts) + len(high_alerts) + len(medium_alerts)) + "\n\n"
          pr_comment += "### Tools: CodeQL, Semgrep, Trivy, 2MS\n\n"
          pr_comment += "---\n*AI analysis by Claude 3.7*\n"
          
          with open('pr_security_review.md', 'w') as f:
              f.write(pr_comment)
          
          print(pr_comment)
          EOF
      
      - name: Run AI analysis
        env:
          ANTHROPIC_API_KEY: ${{ secrets.ANTHROPIC_API_KEY }}
        run: python3 analyze.py
      
      - name: Post PR Review Comment
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');
            const comment = fs.readFileSync('pr_security_review.md', 'utf8');
            
            const { data: comments } = await github.rest.issues.listComments({
              owner: context.repo.owner,
              repo: context.repo.repo,
              issue_number: context.issue.number
            });
            
            const botComment = comments.find(c => c.body.includes('AI Security Review'));
            
            if (botComment) {
              await github.rest.issues.updateComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                comment_id: botComment.id,
                body: comment
              });
            } else {
              await github.rest.issues.createComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                issue_number: context.issue.number,
                body: comment
              });
            }

  ai-inline-review:
    name: AI Inline Code Comments
    runs-on: ubuntu-latest
    needs: [semgrep-scan, trivy-scan, codeql, tms-scan]
    if: github.event_name == 'pull_request'
    permissions:
      contents: read
      pull-requests: write
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
      
      - name: Download SARIF files
        uses: actions/download-artifact@v4
        with:
          path: sarif-results
      
      - name: Install dependencies
        run: pip install anthropic
      
      - name: Create inline comments script
        run: |
          cat > inline.py << 'EOF'
          import anthropic
          import os
          import json
          import glob
          from time import sleep
          
          api_key = os.environ.get("ANTHROPIC_API_KEY")
          if not api_key:
              print("No API key")
              with open('review_comments.json', 'w') as f:
                  json.dump([], f)
              exit(0)
          
          client = anthropic.Anthropic(api_key=api_key)
          
          review_comments = []
          processed = 0
          max_comments = 15
          
          for sarif_file in glob.glob("sarif-results/**/*.sarif", recursive=True):
              if processed >= max_comments: break
              try:
                  with open(sarif_file) as f:
                      data = json.load(f)
                      tool = data['runs'][0]['tool']['driver']['name']
                      
                      for result in data['runs'][0].get('results', []):
                          if processed >= max_comments: break
                          
                          rule_id = result.get('ruleId', 'unknown')
                          message = result.get('message', {}).get('text', '')
                          level = result.get('level', 'warning')
                          
                          location = result.get('locations', [{}])[0]
                          phys_loc = location.get('physicalLocation', {})
                          file_path = phys_loc.get('artifactLocation', {}).get('uri', '')
                          line = phys_loc.get('region', {}).get('startLine', 1)
                          
                          if not file_path or line < 1: continue
                          if level not in ['error', 'warning']: continue
                          
                          prompt = "Security alert: " + tool + " - " + rule_id + "\n" + message + "\n\nIn 1-2 sentences: Real issue or false positive? How to fix?"
                          
                          try:
                              ai_msg = client.messages.create(
                                  model="claude-3-7-sonnet-20250219",
                                  max_tokens=200,
                                  messages=[{"role": "user", "content": prompt}]
                              )
                              
                              analysis = ai_msg.content[0].text
                              emoji = "🔴" if level == "error" else "🟠"
                              
                              review_comments.append({
                                  "path": file_path,
                                  "line": line,
                                  "body": emoji + " **" + tool + "** - `" + rule_id + "`\n\n" + analysis + "\n\n*AI analysis*"
                              })
                              
                              processed += 1
                              print("Comment " + str(processed))
                              sleep(1.5)
                          except: pass
              except: pass
          
          with open('review_comments.json', 'w') as f:
              json.dump(review_comments, f)
          
          print("Created " + str(len(review_comments)) + " comments")
          EOF
      
      - name: Run inline analysis
        env:
          ANTHROPIC_API_KEY: ${{ secrets.ANTHROPIC_API_KEY }}
        run: python3 inline.py
      
      - name: Post Inline Comments
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');
            const comments = JSON.parse(fs.readFileSync('review_comments.json', 'utf8'));
            
            for (const comment of comments) {
              try {
                await github.rest.pulls.createReviewComment({
                  owner: context.repo.owner,
                  repo: context.repo.repo,
                  pull_number: context.issue.number,
                  body: comment.body,
                  path: comment.path,
                  line: comment.line,
                  commit_id: context.payload.pull_request.head.sha
                });
              } catch (error) {
                console.log('Failed: ' + error.message);
              }
            }
