name: DevSecOps Pipeline

on:
  push:
    branches: [ "main" ]
  pull_request:
    branches: [ "main" ]
  schedule:
    - cron: '30 1 * * 0'

permissions:
  contents: read
  packages: write
  security-events: write

jobs:
  tms-scan:
    name: 2MS Secret Scan
    runs-on: ubuntu-latest
    permissions:
      contents: read
      security-events: write
      actions: read
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
      
      - name: Run 2MS and save output
        continue-on-error: true
        run: |
          mkdir -p results
          chmod 777 results
          docker run --rm -v $(pwd):/repo checkmarx/2ms:2.8.1 git /repo --stdout-format json > results/2ms-raw.txt || true
          grep -A 999999 '^{' results/2ms-raw.txt > results/2ms-clean.json || echo '{"results":{}}' > results/2ms-clean.json
      
      - name: Convert to SARIF
        run: |
          python3 << 'PYTHON_SCRIPT'
          import json
          
          sarif = {
              "$schema": "https://raw.githubusercontent.com/oasis-tcs/sarif-spec/master/Schemata/sarif-schema-2.1.0.json",
              "version": "2.1.0",
              "runs": [{
                  "tool": {
                      "driver": {
                          "name": "2MS",
                          "informationUri": "https://checkmarx.com/product/2ms/",
                          "version": "2.8.1",
                          "rules": []
                      }
                  },
                  "results": []
              }]
          }
          
          try:
              with open('results/2ms-clean.json', 'r') as f:
                  data = json.load(f)
                  results = data.get('results', {})
                  
                  for commit_hash, findings in results.items():
                      for finding in findings:
                          rule_id = finding.get('ruleId', 'secret-detected')
                          source = finding.get('source', 'unknown')
                          start_line = finding.get('startLine', 1)
                          file_path = source.split(':')[-1] if ':' in source else 'unknown'
                          
                          if not any(r['id'] == rule_id for r in sarif['runs'][0]['tool']['driver']['rules']):
                              sarif['runs'][0]['tool']['driver']['rules'].append({
                                  "id": rule_id,
                                  "name": rule_id,
                                  "shortDescription": {"text": "Detected " + rule_id},
                                  "defaultConfiguration": {"level": "warning"}
                              })
                          
                          sarif['runs'][0]['results'].append({
                              "ruleId": rule_id,
                              "message": {"text": "Found " + rule_id + " in " + file_path},
                              "locations": [{
                                  "physicalLocation": {
                                      "artifactLocation": {"uri": file_path},
                                      "region": {"startLine": max(1, start_line)}
                                  }
                              }],
                              "level": "warning"
                          })
                  
                  print("Converted " + str(len(sarif['runs'][0]['results'])) + " findings to SARIF")
          except Exception as e:
              print("Error: " + str(e))
          
          with open('2ms-results.sarif', 'w') as f:
              json.dump(sarif, f, indent=2)
          PYTHON_SCRIPT
      
      - name: Upload 2MS SARIF to Code Scanning
        if: always()
        uses: github/codeql-action/upload-sarif@v3
        with:
          sarif_file: 2ms-results.sarif
          category: 2ms
      
      - name: Save 2MS SARIF as Artifact
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: 2ms-sarif
          path: 2ms-results.sarif

  build-and-push:
    name: Build and Push to GHCR
    runs-on: ubuntu-latest
    needs: tms-scan
    permissions:
      contents: read
      packages: write
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
      
      - name: Log in to GHCR
        uses: docker/login-action@v3
        with:
          registry: ghcr.io
          username: ${{ github.actor }}
          password: ${{ secrets.GITHUB_TOKEN }}
      
      - name: Build and push
        uses: docker/build-push-action@v5
        with:
          context: .
          file: ./Dockerfile
          push: true
          tags: |
            ghcr.io/${{ github.repository }}:latest
            ghcr.io/${{ github.repository }}:${{ github.sha }}

  semgrep-scan:
    name: Semgrep SAST Scan
    runs-on: ubuntu-latest
    needs: tms-scan
    permissions:
      contents: read
      security-events: write
      actions: read
    container:
      image: returntocorp/semgrep
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
      
      - name: Run Semgrep
        run: semgrep scan --sarif --output semgrep.sarif
      
      - name: Upload SARIF to Code Scanning
        if: always()
        uses: github/codeql-action/upload-sarif@v3
        with:
          sarif_file: semgrep.sarif
      
      - name: Save Semgrep SARIF as Artifact
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: semgrep-sarif
          path: semgrep.sarif

  trivy-scan:
    name: Trivy Container Scan
    runs-on: ubuntu-latest
    needs: build-and-push
    permissions:
      contents: read
      security-events: write
      actions: read
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
      
      - name: Run Trivy
        uses: aquasecurity/trivy-action@master
        with:
          image-ref: 'ghcr.io/${{ github.repository }}:latest'
          format: 'sarif'
          output: 'trivy.sarif'
          severity: 'CRITICAL,HIGH'
          exit-code: '0'
      
      - name: Upload SARIF to Code Scanning
        if: always()
        uses: github/codeql-action/upload-sarif@v3
        with:
          sarif_file: 'trivy.sarif'
      
      - name: Save Trivy SARIF as Artifact
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: trivy-sarif
          path: trivy.sarif

  codeql:
    name: CodeQL SAST Scan
    runs-on: ubuntu-latest
    permissions:
      contents: read
      security-events: write
      actions: read
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
      
      - name: Initialize CodeQL
        uses: github/codeql-action/init@v3
        with:
          languages: 'javascript'
          queries: security-extended
      
      - name: Perform CodeQL Analysis
        uses: github/codeql-action/analyze@v3

  ai-security-analysis:
    name: AI Security Analysis
    runs-on: ubuntu-latest
    needs: [semgrep-scan, trivy-scan, codeql, tms-scan]
    if: always()
    permissions:
      contents: read
      security-events: write
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
      
      - name: Download SARIF results
        uses: actions/download-artifact@v4
        with:
          path: sarif-results
      
      - name: Install dependencies
        run: pip install anthropic
      
      - name: Create analysis script file
        run: |
          cat > /tmp/analyze.py << 'ENDOFPYTHON'
          import anthropic
          import os
          import json
          import glob
          
          api_key = os.environ.get("ANTHROPIC_API_KEY")
          if not api_key:
              print("No API key configured")
              with open('AI_SECURITY_REPORT.md', 'w') as f:
                  f.write("AI Security Analysis - API key not configured")
              exit(0)
          
          client = anthropic.Anthropic(api_key=api_key)
          
          critical_alerts = []
          high_alerts = []
          medium_alerts = []
          all_findings = []
          all_tools = set()
          
          for sarif_file in glob.glob("sarif-results/**/*.sarif", recursive=True):
              try:
                  with open(sarif_file, 'r') as f:
                      data = json.load(f)
                      tool = data['runs'][0]['tool']['driver']['name']
                      all_tools.add(tool)
                      results = data['runs'][0].get('results', [])
                      
                      for result in results[:50]:
                          rule_id = result.get('ruleId', 'unknown')
                          message = result.get('message', {}).get('text', '')
                          level = result.get('level', 'warning')
                          
                          location = result.get('locations', [{}])[0]
                          phys_loc = location.get('physicalLocation', {})
                          file_path = phys_loc.get('artifactLocation', {}).get('uri', 'unknown')
                          line = phys_loc.get('region', {}).get('startLine', 0)
                          
                          finding = {
                              "tool": tool,
                              "rule": rule_id,
                              "message": message[:150],
                              "file": file_path,
                              "line": line,
                              "severity": level
                          }
                          
                          all_findings.append(finding)
                          
                          if 'error' in level or 'critical' in level.lower():
                              critical_alerts.append(finding)
                          elif 'warning' in level or 'high' in level.lower():
                              high_alerts.append(finding)
                          else:
                              medium_alerts.append(finding)
              except Exception as e:
                  print("Error: " + str(e))
          
          print("Total: " + str(len(all_findings)))
          print("Critical: " + str(len(critical_alerts)))
          print("High: " + str(len(high_alerts)))
          
          critical_json = json.dumps(critical_alerts[:10], indent=2)
          high_json = json.dumps(high_alerts[:10], indent=2)
          tools_list = ', '.join(all_tools)
          
          summary = "SECURITY SCAN RESULTS\n\n"
          summary += "Total Findings: " + str(len(all_findings)) + "\n"
          summary += "Critical: " + str(len(critical_alerts)) + "\n"
          summary += "High: " + str(len(high_alerts)) + "\n"
          summary += "Medium: " + str(len(medium_alerts)) + "\n\n"
          summary += "Tools: " + tools_list + "\n\n"
          summary += "Top Critical:\n" + critical_json + "\n\n"
          summary += "Top High:\n" + high_json
          
          instruction = "You are a senior security engineer. Analyze these security findings and provide:\n\n"
          instruction += "EXECUTIVE SUMMARY - Three sentences on overall security posture\n"
          instruction += "CRITICAL FINDINGS - Top 5 dangerous vulnerabilities needing immediate action\n"
          instruction += "RISK SCORE - Rate 1 to 10 with justification\n"
          instruction += "FALSE POSITIVES - Identify likely false positives and why\n"
          instruction += "REMEDIATION PLAN - Prioritized 30/60/90 day roadmap\n"
          instruction += "RECOMMENDATIONS - Five actionable improvements\n\n"
          instruction += "Be direct and interview-ready.\n\n"
          instruction += "Scan Results:\n"
          
          full_prompt = instruction + summary
          
          message = client.messages.create(
              model="claude-3-7-sonnet-20250219",
              max_tokens=3500,
              messages=[{"role": "user", "content": full_prompt}]
          )
          
          analysis = message.content[0].text
          
          report = "# AI-Powered Security Analysis Report\n\n"
          report += analysis + "\n\n"
          report += "---\n\n"
          report += "## Statistics\n\n"
          report += "### By Severity\n"
          report += "- Critical: " + str(len(critical_alerts)) + "\n"
          report += "- High: " + str(len(high_alerts)) + "\n"
          report += "- Medium: " + str(len(medium_alerts)) + "\n\n"
          
          tool_counts = {}
          for finding in all_findings:
              tool = finding['tool']
              tool_counts[tool] = tool_counts.get(tool, 0) + 1
          
          report += "### By Tool\n"
          for tool, count in sorted(tool_counts.items(), key=lambda x: x[1], reverse=True):
              report += "- " + tool + ": " + str(count) + "\n"
          
          report += "\n### Tools Used\n"
          report += "- CodeQL - Semantic analysis\n"
          report += "- Semgrep - Pattern matching\n"
          report += "- Trivy - Container scanning\n"
          report += "- 2MS - Secret detection\n\n"
          report += "---\n"
          report += "AI analysis by Claude 3.7 Sonnet\n"
          
          with open('AI_SECURITY_REPORT.md', 'w') as f:
              f.write(report)
          
          print("Report generated successfully")
          ENDOFPYTHON
      
      - name: Run AI Analysis
        env:
          ANTHROPIC_API_KEY: ${{ secrets.ANTHROPIC_API_KEY }}
        run: python3 /tmp/analyze.py
      
      - name: Upload AI Report
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: ai-security-analysis-report
          path: AI_SECURITY_REPORT.md
      
      - name: Display Summary
        if: always()
        run: |
          echo "=========================================="
          echo "AI SECURITY ANALYSIS COMPLETE"
          echo "=========================================="
          if [ -f AI_SECURITY_REPORT.md ]; then
            head -100 AI_SECURITY_REPORT.md
          fi
